<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN">
<HTML
><HEAD
><TITLE
>PVM Administration at RFPK</TITLE
><META
NAME="GENERATOR"
CONTENT="Modular DocBook HTML Stylesheet Version 1.76b+
"></HEAD
><BODY
CLASS="article"
BGCOLOR="#FFFFFF"
TEXT="#000000"
LINK="#0000FF"
VLINK="#840084"
ALINK="#0000FF"
><DIV
CLASS="ARTICLE"
><DIV
CLASS="TITLEPAGE"
><H1
CLASS="title"
><A
NAME="AEN1"
></A
>PVM Administration at RFPK</H1
><DIV
><TABLE
BORDER="0"
BGCOLOR="#E0E0E0"
WIDTH="80%"
CELLSPACING="10"
CELLPADDING="0"
ALIGN="CENTER"
><TR
><TD
VALIGN="TOP"
><B
>Abstract</B
></TD
></TR
><TR
><TD
VALIGN="TOP"
><P
>&#13;	The administration of the Parallel Virtual Machine (PVM) in the
	RFPK lab is described.
      </P
></TD
></TR
></TABLE
></DIV
><DIV
CLASS="revhistory"
><TABLE
WIDTH="100%"
BORDER="0"
><TR
><TH
ALIGN="LEFT"
VALIGN="TOP"
COLSPAN="3"
><B
>Revision History</B
></TH
></TR
><TR
><TD
ALIGN="LEFT"
>Revision 1.0</TD
><TD
ALIGN="LEFT"
>November 19, 2004</TD
><TD
ALIGN="LEFT"
>Revised by: afw</TD
></TR
><TR
><TD
ALIGN="LEFT"
COLSPAN="3"
>Initial version.</TD
></TR
></TABLE
></DIV
><HR
WIDTH="75%"
ALIGN="CENTER"
COLOR="#000000"
SIZE="1"></DIV
><DIV
CLASS="TOC"
><DL
><DT
><B
>Table of Contents</B
></DT
><DT
><A
HREF="#AEN12"
>Introduction</A
></DT
><DT
><A
HREF="#AEN18"
>Network Security</A
></DT
><DT
><A
HREF="#AEN24"
>Shared File Hierarchy</A
></DT
><DT
><A
HREF="#AEN31"
>Software Installation</A
></DT
><DT
><A
HREF="#AEN48"
>NFS Configuration Required for the All Nodes</A
></DT
><DT
><A
HREF="#AEN61"
>Additional NFS Configuration for the Head Node</A
></DT
><DT
><A
HREF="#configure-nfs"
>Additional NFS Configuration on Ordinary Nodes</A
></DT
><DT
><A
HREF="#every-node"
>Configuration Required for Every Node</A
></DT
><DD
><DL
><DT
><A
HREF="#AEN115"
>Correct <TT
CLASS="filename"
>/etc/hosts</TT
></A
></DT
><DT
><A
HREF="#AEN128"
>Create a home directory for pvm</A
></DT
><DT
><A
HREF="#AEN135"
>Install keychain</A
></DT
></DL
></DD
><DT
><A
HREF="#AEN142"
>Configuration for the Head Node</A
></DT
><DD
><DL
><DT
><A
HREF="#AEN148"
>Copy skeleton files to <TT
CLASS="filename"
>$PVM_ROOT</TT
></A
></DT
><DT
><A
HREF="#AEN154"
>Edit <TT
CLASS="filename"
>/home/pvm/.bashrc</TT
></A
></DT
><DT
><A
HREF="#AEN167"
>Create a shared <TT
CLASS="filename"
>.ssh</TT
> directory</A
></DT
><DT
><A
HREF="#AEN172"
>Create an ssh key pair</A
></DT
><DT
><A
HREF="#AEN176"
>Create a shared <TT
CLASS="filename"
>authorized_keys</TT
> file</A
></DT
><DT
><A
HREF="#AEN180"
>Configure keychain</A
></DT
></DL
></DD
><DT
><A
HREF="#ssh-config"
>SSH Configuration for Ordinary Nodes</A
></DT
><DT
><A
HREF="#symbolic-links"
>Symbolic Links for Every Node</A
></DT
><DT
><A
HREF="#AEN204"
>Adding an Ordinary Node</A
></DT
></DL
></DIV
><DIV
CLASS="sect1"
><H2
CLASS="sect1"
><A
NAME="AEN12"
></A
>Introduction</H2
><P
>&#13;      The Parallel Virtual Machine (pvm) is a software system which allows
      spk to be distributed over any arbitrary collection of computers 
      running the linux or unix operating system.  Each computer is a node
      in the pvm, capable of participating in the
      spk computation.  With the system correctly configured, nodes can
      be added and deleted at will. 
    </P
><P
>&#13;      This document assumes that all nodes in the pvm are running the same
      or closely related versions of the same operating system.  In the 
      current version of this document, that operating system is RedHat Enterprise Linux, Version 3 (RHEL3).
    </P
><P
>&#13;      A key feature of the configuration described
      is that all of the software and many of the
      configuration files are shared via the Network Files System (NFS).  This
      greatly reduces the overall system administration required.
    </P
><P
>&#13;      Another important feature of this configuration is that different
      processor architectures are accommodated in the same configuration.
    </P
></DIV
><DIV
CLASS="sect1"
><HR><H2
CLASS="sect1"
><A
NAME="AEN18"
></A
>Network Security</H2
><P
>&#13;      An important part of the pvm architecture is a set of daemons,
      one on each host, which provide task life-cycle and inter-task
      communications services.  In the basic configuration, these
      daemons communicate between themselves using the 
      <I
CLASS="emphasis"
>rsh</I
> internet service, without passwords. 
      This is very insecure.
    </P
><P
>&#13;      As an alternative,
      <I
CLASS="emphasis"
>ssh</I
> can be used and that is the approach
      described in this document.  With ssh, communication between
      nodes is secure, even if they are on a subnetwork that is open
      to the public internet.  Public key encryption is used, so that
      a passcode is required only when the head node is booted.  When,
      on the other hand, an ordinary node is booted, the daemon on
      the head node discovers that it can no longer communicate with
      the daemon on the ordinary node, and deletes it from the 
      PVM.  After the ordinary node is back up, the pvm console program
      can be used to add it to the pvm once again.
    </P
></DIV
><DIV
CLASS="sect1"
><HR><H2
CLASS="sect1"
><A
NAME="AEN24"
></A
>Shared File Hierarchy</H2
><P
>&#13;      At RFPK, the pvm software is installed centrally on cspkserver.
      Each of the other hosts accesses the software via NFS.
      The shared file hierarchy is mounted on the directory node normally
      referred to by the environment variable <TT
CLASS="varname"
>PVM_ROOT</TT
>.
      Within this hierarchy, items which differ from one supported 
      architecture to another are differentiated by the inclusion
      of architecture specific nodes in the pathnames.  For example,
      pvm system executables are found in the directory
      <TT
CLASS="filename"
>$PVM_ROOT/lib/$PVM_ARCH</TT
>.  Substituting
      values for environment variables in use for Pentium machines at
      RFPK, this path resolves to 
      <TT
CLASS="filename"
>/usr/share/pvm3/lib/LINUXI386</TT
>.
      Similarly, spk executables reside in the library
      <TT
CLASS="filename"
>$PVM_ROOT/bin/$PVM_ARCH</TT
>.
    </P
></DIV
><DIV
CLASS="sect1"
><HR><H2
CLASS="sect1"
><A
NAME="AEN31"
></A
>Software Installation</H2
><P
>&#13;      All pvm software at RFPK is installed on cspkserver, which acts 
      as the head node of the pvm.  At present, two processor architectures
      are supported. Pvm designates the Intel Pentium architecture as
      LINUXI386 and the Amd/Intel 64-bit architecture as LINUXX86_64.
      The software for both of these architectures is installed on 
      cspkserver so that both architectures are available to the
      other hosts via NFS.  If additional architectures were to be 
      added, their software would also be installed on cspkserver.
    </P
><P
>&#13;      Because our systems all run RedHat Enterprise Linux, Version 3 (RHEL3), the easiest
      and most reliable way to install and update the software is to
      download packages as <TT
CLASS="filename"
>.rpm</TT
> files and to 
      install them with the RedHat Packet Manager (rpm).
    </P
><P
>&#13;      Here is how the software was installed on cspkserver. If, for 
      some reason, the software had to be reinstalled from scratch,
      this would be the procedure to follow.
      <P
></P
><OL
TYPE="1"
><LI
><P
>&#13;	    Download the most recent pvm packages from RedHat.
	    At the time of writing (February 4, 2005), the 
	    most recent were
	    <TT
CLASS="filename"
>pvm-3.4.4-22.i386.rpm</TT
> and
	    <TT
CLASS="filename"
>pvm-3.4.4-22.x86_64.rpm</TT
>.
	  </P
></LI
><LI
><P
>&#13;	    Install the package for the LINUXX86_64 architecture. As
	    root, in a terminal window do the following:
	    <TABLE
BORDER="0"
BGCOLOR="#E0E0E0"
WIDTH="100%"
><TR
><TD
><PRE
CLASS="screen"
>&#13;rpm -Uhv pvm-3.4.4-22.x86_64.rpm
	    </PRE
></TD
></TR
></TABLE
>
	  </P
></LI
><LI
><P
>&#13;	    Install the package for the LINUXI386 architecture:
	    <TABLE
BORDER="0"
BGCOLOR="#E0E0E0"
WIDTH="100%"
><TR
><TD
><PRE
CLASS="screen"
>&#13;rpm -Uhv pvm-3.4.4-22.i386.rpm
	    </PRE
></TD
></TR
></TABLE
>
	  </P
></LI
></OL
>
    </P
></DIV
><DIV
CLASS="sect1"
><HR><H2
CLASS="sect1"
><A
NAME="AEN48"
></A
>NFS Configuration Required for the All Nodes</H2
><P
>&#13;      As root, in a terminal window, do the following:
      <P
></P
><OL
TYPE="1"
><LI
><P
>&#13;	    Start NFS, if it is not already running:o
	    <TABLE
BORDER="0"
BGCOLOR="#E0E0E0"
WIDTH="100%"
><TR
><TD
><PRE
CLASS="screen"
>&#13;/etc/rc.d/init.d/nfs start
	    </PRE
></TD
></TR
></TABLE
>
	  </P
></LI
><LI
><P
>&#13;	    Insure that NFS will restart automatically, each time the 
	    system boots:
	    <TABLE
BORDER="0"
BGCOLOR="#E0E0E0"
WIDTH="100%"
><TR
><TD
><PRE
CLASS="screen"
>&#13;/sbin/chkconfig nfs on
	    </PRE
></TD
></TR
></TABLE
>
	  </P
></LI
><LI
><P
>&#13;	    Restart the port mapper:
	    <TABLE
BORDER="0"
BGCOLOR="#E0E0E0"
WIDTH="100%"
><TR
><TD
><PRE
CLASS="screen"
>&#13;/etc/rc.d/init.d/portmap restart
	    </PRE
></TD
></TR
></TABLE
>
	  </P
></LI
></OL
>
    </P
></DIV
><DIV
CLASS="sect1"
><HR><H2
CLASS="sect1"
><A
NAME="AEN61"
></A
>Additional NFS Configuration for the Head Node</H2
><P
>&#13;	As root in a terminal window, perform the following:
      <P
></P
><OL
TYPE="1"
><LI
><P
>&#13;	    Each node must have an entry in the <TT
CLASS="filename"
>/etc/hosts</TT
>
	    file.  For any node that is not already so declared, use your
	    favorite text editor to add a line such as the following, which
	    relates the IP address with the name by which you wish to 
	    refer to it:
	    <TABLE
BORDER="0"
BGCOLOR="#E0E0E0"
WIDTH="100%"
><TR
><TD
><PRE
CLASS="screen"
>&#13;	      192.168.1.5          rose
	    </PRE
></TD
></TR
></TABLE
>
	  </P
></LI
><LI
><A
NAME="exports"
></A
><P
>&#13;	  Edit the <TT
CLASS="filename"
>/etc/exports</TT
> file to list all of
	  the nodes that will need access to the software.  For 
	  <I
CLASS="emphasis"
>each</I
> such node, add a line such as
	  this:
	  <TABLE
BORDER="0"
BGCOLOR="#E0E0E0"
WIDTH="100%"
><TR
><TD
><PRE
CLASS="screen"
>&#13;	    /usr/share/pvm3        rose(rw,sync,no_root_squash)
	  </PRE
></TD
></TR
></TABLE
>
	  Note that <TT
CLASS="filename"
>/usr/share/pvm3</TT
> is the file
	  hierarchy which will be shared, and <I
CLASS="emphasis"
>rose</I
>
	  is the host name of a node which will be allowed to 
	  access it.
	</P
></LI
><LI
><A
NAME="exportfs"
></A
><P
>&#13;	  Export the file hierarchy:
	  <TABLE
BORDER="0"
BGCOLOR="#E0E0E0"
WIDTH="100%"
><TR
><TD
><PRE
CLASS="screen"
>&#13;	    /usr/sbin/exportfs -a
	  </PRE
></TD
></TR
></TABLE
>
	</P
></LI
></OL
>
    </P
></DIV
><DIV
CLASS="sect1"
><HR><H2
CLASS="sect1"
><A
NAME="configure-nfs"
></A
>Additional NFS Configuration on Ordinary Nodes</H2
><P
>&#13;      This section covers NFS configuration for all nodes other than
      the head node (cspkserver).  All the following should be 
      performed by the root user, from a terminal window.
    </P
><P
>&#13;      <P
></P
><OL
TYPE="1"
><LI
><P
>&#13;	    Hide a preexisting installation of pvm on the node, if
	    one exists:
	    <TABLE
BORDER="0"
BGCOLOR="#E0E0E0"
WIDTH="100%"
><TR
><TD
><PRE
CLASS="screen"
>&#13;mv /usr/share/pvm3 /usr/share/pvm3.hide
	    </PRE
></TD
></TR
></TABLE
>
	  </P
></LI
><LI
><P
>&#13;	    The <TT
CLASS="filename"
>/etc/hosts</TT
> file must contain an entry for
	    <I
CLASS="emphasis"
>cspkserver</I
>.  If such an entry is not already
	    there, edit <TT
CLASS="filename"
>/etc/hosts</TT
> to add the line 
	    (or similar, if this IP address is incorrect):
	    <TABLE
BORDER="0"
BGCOLOR="#E0E0E0"
WIDTH="100%"
><TR
><TD
><PRE
CLASS="screen"
>&#13;192.168.1.18     cspk cspkserver
	    </PRE
></TD
></TR
></TABLE
>
	  </P
></LI
><LI
><P
>&#13;	    Create a node on which to mount <TT
CLASS="filename"
>PVM_ROOT</TT
>:
	    <TABLE
BORDER="0"
BGCOLOR="#E0E0E0"
WIDTH="100%"
><TR
><TD
><PRE
CLASS="screen"
>&#13;mkdir /usr/share/pvm3
	    </PRE
></TD
></TR
></TABLE
>
	  </P
></LI
><LI
><P
>&#13;	    All nodes other than the head node must perform an NFS mount of
	    PVM_ROOT.  As root, edit <TT
CLASS="filename"
>/etc/fstab</TT
>,
	    adding the following line:
	    <TABLE
BORDER="0"
BGCOLOR="#E0E0E0"
WIDTH="100%"
><TR
><TD
><PRE
CLASS="screen"
>&#13;cspkserver:/usr/share/pvm3  /usr/share/pvm3  nfs rsize=8194,wsize=8192,timeo=14,intr
	    </PRE
></TD
></TR
></TABLE
>
	  </P
></LI
><LI
><P
>&#13;	    If, on the <I
CLASS="emphasis"
>head node</I
>, there is no entry for
	    this ordinary node in the <TT
CLASS="filename"
>/etc/exports</TT
> file,
	    <A
HREF="#exports"
>&#13;	      add an entry now 
	    </A
>
	    ; then 
	    <A
HREF="#exportfs"
>export it</A
>.
	  </P
></LI
><LI
><P
>&#13;	    Verify that you can mount PVM_ROOT by executing the following 
	    command, as root:
	    <TABLE
BORDER="0"
BGCOLOR="#E0E0E0"
WIDTH="100%"
><TR
><TD
><PRE
CLASS="screen"
>&#13;mount /usr/share/pvm3
	    </PRE
></TD
></TR
></TABLE
>
	    then use <B
CLASS="command"
>ls</B
> to verify that the directory
	    contains files.
	  </P
></LI
></OL
>
    </P
></DIV
><DIV
CLASS="sect1"
><HR><H2
CLASS="sect1"
><A
NAME="every-node"
></A
>Configuration Required for Every Node</H2
><P
>&#13;      This section covers configuration steps that must be taken
      for <I
CLASS="emphasis"
>all nodes, including the head node</I
>.
    </P
><DIV
CLASS="sect2"
><HR><H3
CLASS="sect2"
><A
NAME="AEN115"
></A
>Correct <TT
CLASS="filename"
>/etc/hosts</TT
></H3
><P
>&#13;	In linux, the host name of a system as well as its aliases can
	be associated in the <TT
CLASS="filename"
>/etc/hosts</TT
> file with
	either <TT
CLASS="filename"
>127.0.0.1</TT
>, which is the IP address
	of the <I
CLASS="emphasis"
>lo</I
> interface, or with the IP
	address of a network interface, such as <I
CLASS="emphasis"
>eth0</I
>.
	For pvm to work correctly, only the latter choice is acceptable.
	In other words, the host name and its aliases
	must be associated with the IP address by which the node is
	addressed by the other nodes. 
      </P
><P
>&#13;	As root, edit <TT
CLASS="filename"
>/etc/hosts</TT
> so that the 
	localhost entry looks like this:
	<TABLE
BORDER="0"
BGCOLOR="#E0E0E0"
WIDTH="100%"
><TR
><TD
><PRE
CLASS="screen"
>&#13;127.0.0.1       localhost localhost.localdomain
	</PRE
></TD
></TR
></TABLE
>
	and the entry for a node (<I
CLASS="emphasis"
>anynode</I
>, for example):
	<TABLE
BORDER="0"
BGCOLOR="#E0E0E0"
WIDTH="100%"
><TR
><TD
><PRE
CLASS="screen"
>&#13;192.168.1.18    anynode
	</PRE
></TD
></TR
></TABLE
>
      </P
></DIV
><DIV
CLASS="sect2"
><HR><H3
CLASS="sect2"
><A
NAME="AEN128"
></A
>Create a home directory for pvm</H3
><P
>&#13;	As part of the installation of RedHat Enterprise Linux, Version 3 (RHEL3), a user named pvm is created.
	It is given <TT
CLASS="filename"
>PVM_ROOT</TT
> as its home directory. 
	This will not work for our purposes, because we share 
	the <TT
CLASS="filename"
>PVM_ROOT</TT
> file hierarchy via NFS. Certain
	configuration files are changed by the nodes during their normal
	operation.  If these files were shared, the nodes would interfere
	with each other.  For this reason, it is necessary to create
	a separate home directory for every node.
      </P
><P
>&#13;	As root:
	<TABLE
BORDER="0"
BGCOLOR="#E0E0E0"
WIDTH="100%"
><TR
><TD
><PRE
CLASS="screen"
>&#13;mkdir /home/pvm
usermod -d /home/pvm pvm
	</PRE
></TD
></TR
></TABLE
>
      </P
></DIV
><DIV
CLASS="sect2"
><HR><H3
CLASS="sect2"
><A
NAME="AEN135"
></A
>Install keychain</H3
><P
>&#13;	ssh is used for communication between nodes of the
	pvm.  Normally, ssh requires a password every time that a
	communications channel is established.  If a program called
	keychain is installed on each node, however, the password
	only needs to be provided for the first communication 
	between two hosts after a system boot by the destination
	host.  An <TT
CLASS="filename"
>.rpm</TT
> package can be downloaded
	from the keychain
	<A
HREF="http://www.gentoo.org/proj/en/keychain.xml"
TARGET="_top"
>&#13;	  web site
	</A
>
	or it can be copied from whitechuck (fileserver):
	<TABLE
BORDER="0"
BGCOLOR="#E0E0E0"
WIDTH="100%"
><TR
><TD
><PRE
CLASS="screen"
>&#13;# as an ordinary user
scp 'fileserver:/opt/download/keychain*.rpm' .
	</PRE
></TD
></TR
></TABLE
>
	Once you have the file on the node, as root you can install
	it with the command
	<TABLE
BORDER="0"
BGCOLOR="#E0E0E0"
WIDTH="100%"
><TR
><TD
><PRE
CLASS="screen"
>&#13;# as root
rpm -Uhv keychain*.rpm
	</PRE
></TD
></TR
></TABLE
>
      </P
></DIV
></DIV
><DIV
CLASS="sect1"
><HR><H2
CLASS="sect1"
><A
NAME="AEN142"
></A
>Configuration for the Head Node</H2
><P
>&#13;      In the following, it is assumed that you will be working as the
      <I
CLASS="emphasis"
>root</I
> user, from a terminal window, and that 
      for convenience sake, you have defined <TT
CLASS="varname"
>PVM_ROOT</TT
>:
      <TABLE
BORDER="0"
BGCOLOR="#E0E0E0"
WIDTH="100%"
><TR
><TD
><PRE
CLASS="screen"
>&#13;PVM_ROOT=/usr/share/pvm3
      </PRE
></TD
></TR
></TABLE
>
    </P
><DIV
CLASS="sect2"
><HR><H3
CLASS="sect2"
><A
NAME="AEN148"
></A
>Copy skeleton files to <TT
CLASS="filename"
>$PVM_ROOT</TT
></H3
><P
>&#13;	We will need some configuration files to enable the pvm user
	to run the pvm console program.  The following commands will copy
	the necessary files from the skeleton directory to 
	<TT
CLASS="filename"
>PVM_ROOT</TT
>.  They will later be linked into 
	the home directory by means of symbolic links.
	<TABLE
BORDER="0"
BGCOLOR="#E0E0E0"
WIDTH="100%"
><TR
><TD
><PRE
CLASS="screen"
>&#13;cp /etc/skel/.bash* $PVM_ROOT
cat $PVM_ROOT/lib/bashrc.stub &#62;&#62; $PVM_ROOT/.bashrc  
	</PRE
></TD
></TR
></TABLE
>
      </P
></DIV
><DIV
CLASS="sect2"
><HR><H3
CLASS="sect2"
><A
NAME="AEN154"
></A
>Edit <TT
CLASS="filename"
>/home/pvm/.bashrc</TT
></H3
><P
>&#13;	We can now edit <TT
CLASS="filename"
>$PVM_ROOT/.bashrc</TT
> to define
	several necessary environment variables. Because PVM_ROOT is 
	NFS mounted on all nodes, these variables will be defined for the
	pvm user on all nodes.
      </P
><P
>&#13;	Using your favorite text editor, add the following lines to the
	<TT
CLASS="filename"
>$PVM_ROOT/.bashrc</TT
> just after the section at
	the beginning which sources global definitions from
	<TT
CLASS="filename"
>/etc/bashrc</TT
>:
	<TABLE
BORDER="0"
BGCOLOR="#E0E0E0"
WIDTH="100%"
><TR
><TD
><PRE
CLASS="screen"
>&#13;PVM_ROOT=/usr/share/pvm3
PVM_RSH=/usr/bin/ssh
export PVM_ROOT PVM_RSH
	</PRE
></TD
></TR
></TABLE
>
	Of course, if the value of your <TT
CLASS="varname"
>PVM_ROOT</TT
> is 
	not <TT
CLASS="filename"
>/usr/share/pvm3</TT
>, let the command that
	you use reflect that.
      </P
><P
>&#13;	With your text editor, uncomment the lines that correspond to 
	the following commands by deleting the lead # sign:
	<TABLE
BORDER="0"
BGCOLOR="#E0E0E0"
WIDTH="100%"
><TR
><TD
><PRE
CLASS="screen"
>&#13;export PATH=$PATH:$PVM_ROOT/lib/$PVM_ARCH  # arch-specific
export PATH=$PATH:$PVM_ROOT/bin/$PVM_ARCH
	</PRE
></TD
></TR
></TABLE
>
      </P
></DIV
><DIV
CLASS="sect2"
><HR><H3
CLASS="sect2"
><A
NAME="AEN167"
></A
>Create a shared <TT
CLASS="filename"
>.ssh</TT
> directory</H3
><P
>&#13;	<TABLE
BORDER="0"
BGCOLOR="#E0E0E0"
WIDTH="100%"
><TR
><TD
><PRE
CLASS="screen"
>&#13;cd $PVM_ROOT
mkdir .ssh
chmod 775 .ssh
	</PRE
></TD
></TR
></TABLE
>
      </P
></DIV
><DIV
CLASS="sect2"
><HR><H3
CLASS="sect2"
><A
NAME="AEN172"
></A
>Create an ssh key pair</H3
><P
>&#13;	<TABLE
BORDER="0"
BGCOLOR="#E0E0E0"
WIDTH="100%"
><TR
><TD
><PRE
CLASS="screen"
>&#13;ssh-keygen -t dsa -f .ssh/id_dsa
	</PRE
></TD
></TR
></TABLE
>
      </P
></DIV
><DIV
CLASS="sect2"
><HR><H3
CLASS="sect2"
><A
NAME="AEN176"
></A
>Create a shared <TT
CLASS="filename"
>authorized_keys</TT
> file</H3
><P
>&#13;cat .ssh/id_dsa.pub &#62;&#62; .ssh/authorized_keys
chmod 644 .ssh/authorized_keys
      </P
></DIV
><DIV
CLASS="sect2"
><HR><H3
CLASS="sect2"
><A
NAME="AEN180"
></A
>Configure keychain</H3
><P
>&#13;	The <I
CLASS="emphasis"
>keychain</I
> program makes it possible to 
	initiate multiple ssh sessions without having to enter a pass-code
	more than once. Between reboots of the machine, the pass-code is
	entered the first time a user logs in.  To set this up, we edit the
	<TT
CLASS="filename"
>.bash_profile</TT
> file for the pvm user.
      </P
><P
>&#13;	Using your favorite text editor, append these lines to 
	<TT
CLASS="filename"
>$PVM_ROOT/.bash_profile</TT
>:
	<TABLE
BORDER="0"
BGCOLOR="#E0E0E0"
WIDTH="100%"
><TR
><TD
><PRE
CLASS="screen"
>&#13;keychain ~/.ssh/id_dsa
. ~/.keychain/${HOSTNAME}-sh
	</PRE
></TD
></TR
></TABLE
>
      </P
></DIV
></DIV
><DIV
CLASS="sect1"
><HR><H2
CLASS="sect1"
><A
NAME="ssh-config"
></A
>SSH Configuration for Ordinary Nodes</H2
><P
>&#13;      In the following, it is assumed that you will be working as the
      <I
CLASS="emphasis"
>root</I
> user, from a terminal window, on the
      ordinary node. 
    </P
><P
>&#13;      For convenience sake, define <TT
CLASS="varname"
>PVM_ROOT</TT
>:
      <TABLE
BORDER="0"
BGCOLOR="#E0E0E0"
WIDTH="100%"
><TR
><TD
><PRE
CLASS="screen"
>&#13;PVM_ROOT=/usr/share/pvm3
      </PRE
></TD
></TR
></TABLE
>
    </P
><P
>&#13;      Just like the head node, each ordinary node needs a 
      <TT
CLASS="filename"
>.ssh</TT
> file.
      <TABLE
BORDER="0"
BGCOLOR="#E0E0E0"
WIDTH="100%"
><TR
><TD
><PRE
CLASS="screen"
>&#13;cd /home/pvm
mkdir .ssh
chmod 755 .ssh
      </PRE
></TD
></TR
></TABLE
>
    </P
></DIV
><DIV
CLASS="sect1"
><HR><H2
CLASS="sect1"
><A
NAME="symbolic-links"
></A
>Symbolic Links for Every Node</H2
><P
>&#13;      We have placed several configuration files in <TT
CLASS="filename"
>$PVM_ROOT</TT
>
      rather than <TT
CLASS="filename"
>/home/pvm</TT
> so that they can be shared by
      all nodes.  Now we have to place symbolic links in each home directory
      so that they can be found.
      <TABLE
BORDER="0"
BGCOLOR="#E0E0E0"
WIDTH="100%"
><TR
><TD
><PRE
CLASS="screen"
>&#13;cd /home/pvm 
ln -s $PVM_ROOT/.bash_logout         .bash_logout
ln -s $PVM_ROOT/.bash_profile        .bash_profile
ln -s $PVM_ROOT/.bashrc              .bashrc
cd .ssh
ln -s $PVM_ROOT/.ssh/id_dsa          id_dsa
ln -s $PVM_ROOT/.ssh/id_dsa.pub      id_dsa.pub
ln -s $PVM_ROOT/.ssh/authorized_keys authorized_keys
chown -R pvm.pvm /home/pvm
      </PRE
></TD
></TR
></TABLE
>
    </P
></DIV
><DIV
CLASS="sect1"
><HR><H2
CLASS="sect1"
><A
NAME="AEN204"
></A
>Adding an Ordinary Node</H2
><P
>&#13;      This section contains a check list for adding an ordinary
      node.
    </P
><P
>&#13;      <P
></P
><OL
TYPE="1"
><LI
><P
>&#13;	    As root, in a terminal window, define <TT
CLASS="varname"
>PVM_ROOT</TT
>:
	    <TABLE
BORDER="0"
BGCOLOR="#E0E0E0"
WIDTH="100%"
><TR
><TD
><PRE
CLASS="screen"
>&#13;PVM_ROOT=/usr/share/pvm3
	    </PRE
></TD
></TR
></TABLE
>
	  </P
></LI
><LI
><P
>&#13;	    <A
HREF="#AEN48"
>&#13;	      NFS Configuration Required for All Nodes
	    </A
>
	  </P
></LI
><LI
><P
>&#13;	    <A
HREF="#configure-nfs"
>&#13;	      Additional NFS Configuration on Ordinary Nodes
	    </A
>.
	  </P
></LI
><LI
><P
>&#13;	    <A
HREF="#every-node"
>Configuration Required for Every Node</A
>.
	  </P
></LI
><LI
><P
>&#13;	    <A
HREF="#ssh-config"
>SSH Configuration for Ordinary Nodes</A
>.
	  </P
></LI
><LI
><P
>&#13;	    <A
HREF="#symbolic-links"
>Symbolic Links for Every Node</A
>.
	  </P
></LI
><LI
><P
>&#13;	    Test your configuration.  Suppose that the name of the new node
	    is <I
CLASS="emphasis"
>newnode</I
>.
	    <P
></P
><OL
TYPE="a"
><LI
><P
>&#13;		  Start as the user <I
CLASS="emphasis"
>pvm</I
> on 
		  cspkserver.
		  Use ssh to log into newnode.  
		  <TABLE
BORDER="0"
BGCOLOR="#E0E0E0"
WIDTH="100%"
><TR
><TD
><PRE
CLASS="screen"
>&#13;ssh pvm@newnode
		  </PRE
></TD
></TR
></TABLE
>
		  You will need to supply the pvm pass<I
CLASS="emphasis"
>phrase</I
>.
		</P
></LI
><LI
><P
>&#13;		  Now, in the same window, log into cspkserver.
		  <TABLE
BORDER="0"
BGCOLOR="#E0E0E0"
WIDTH="100%"
><TR
><TD
><PRE
CLASS="screen"
>&#13;ssh cspkserver		    
		  </PRE
></TD
></TR
></TABLE
>
		  You should be asked to supply the pvm pass<I
CLASS="emphasis"
>phrase</I
>.
		</P
></LI
><LI
><P
>&#13;		  Next, in the same window (which is now displaying a shell
		  running on cspkserver), log into newnode:
		  <TABLE
BORDER="0"
BGCOLOR="#E0E0E0"
WIDTH="100%"
><TR
><TD
><PRE
CLASS="screen"
>&#13;ssh newnode
		  </PRE
></TD
></TR
></TABLE
>
		  If everything is working, this time you will not be asked
		  for either a password or a passphrase.
		</P
></LI
><LI
><P
>&#13;		  Finally, from newnode and still in the same window, log into cspkserver:
		  <TABLE
BORDER="0"
BGCOLOR="#E0E0E0"
WIDTH="100%"
><TR
><TD
><PRE
CLASS="screen"
>&#13;ssh cspkserver
		  </PRE
></TD
></TR
></TABLE
>
		  Again, you should not be asked for either a password or
		  a passphrase.
		</P
></LI
></OL
>
	  </P
></LI
></OL
>
    </P
></DIV
></DIV
></BODY
></HTML
>