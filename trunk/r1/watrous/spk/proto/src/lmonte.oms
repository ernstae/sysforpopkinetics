#begin##
%************************************************************************
%                                                                       *
%  From:   Resource Facility for Population Kinetics                    *
%          Department of Bioengineering Box 352255                      *
%          University of Washington                                     *
%          Seattle, WA 98195-2255                                       *
%                                                                       *
%  Copyright (C) 2002, University of Washington,                        *
%  Resource Facility for Population Kinetics. All Rights Reserved.      *
%                                                                       *
%  This software was developed with support from NIH grant RR-12609.    *
%  Please cite this grant in any publication for which this software    *
%  is used and send a notification to the address given above.          *
%                                                                       *
%  Check for updates and notices at:                                    *
%  http://www.rfpk.washington.edu                                       *
%                                                                       *
%************************************************************************

#end##
begin # blocking for automatic include

#begin##

$begin LMonte$$
$escape #$$
$spell
	eps
	mitr
	Laplace 
	Hessian
	ok
	novalue
	obj
	subvector
	Carlo
	Sig
	ranseed
	oms
$$

$section Monte-Carlo Approximation of the Marginal Likelihood Given Fixed Effects$$

$index LMonte$$
$cindex monte-carlo marginal likelihood$$

$syntax/LMonte( ...
function /Model/, ...
/J/, ...
/y/,  ...
/N/, ...
/eps/, ...
/delta/, ...
/mitr/, ...
/level/, ...
/alp/, /alpStep/, ...
/bLow/, /bUp/, /bStep/, ...
/bIn/, /bOut/, ...
/LowOut/, /UpOut/, ...
/LMonteOut/, /SigOut/, ...
/LMonte_alpOut/, /Sig_alpOut/, ...
/LMonte_alp_alpOut/, /Sig_alp_alpOut/ ...
)/$$

$fend 25$$

$head Description$$
Evaluates a Monte-Carlo approximation for the marginal likelihood of the
data given the fixed effects. Reference:
$italic
Approximating The Maximum Likelihood Estimate For Models With Random Parameter
$$

$head Arguments$$
The return value of $italic Model$$ is true if it succeeds and false otherwise.
The return value of $code LMonte$$ is true, if it succeeds,
and false otherwise.
$syntax/

/Model/(/i/, /alp/, /b/, /fOut/, /f_alpOut/, /f_bOut/, /ROut/, /R_alpOut/, /R_bOut/, /DOut/, /D_alpOut/)
/$$
All the arguments to this routine have real or double-precision values. In addition,
the arguments that end in $italic Out$$ are 
$xref/glossary/Output Value/output values/$$.
The following table uses 
$xref/glossary/Population Notation/population notation/$$
$table
$bold Argument$$
	$cend $bold Value$$ 
	$cend $bold Comments$$ $rend
$italic i$$
	$cend $math%i%$$
	$cend index for this individual $rend
$italic alp$$
	$cend $math%alp%$$
	$cend fixed population parameter vector $rend
$italic b$$
	$cend $math%b%$$
	$cend random population parameter vector $rend
$italic fOut$$
	$cend $math%f_i(alp, b)%$$ 
	$cend model for the mean of $math%y_i%$$ given $math%b%$$ $rend
$italic f_alpOut$$ 
	$cend $math%f_i_alp(alp, b)%$$ 
	$cend derivative of $math%f_i(alp, b)%$$ with respect to $math%alp%$$ $rend
$italic f_bOut$$ 
	$cend $math%f_i_b(alp, b)%$$ 
	$cend derivative of $math%f_i(alp, b)%$$ with respect to $math%b%$$ $rend
$italic ROut$$ 
	$cend $math%R_i(alp, b)%$$ 
	$cend model for the variance of $math%y%$$ given $math%b%$$ $rend
$italic R_alpOut$$
	$cend $math%R_i_alp(alp, b)%$$ 
	$cend derivative of $math%R_i(alp, b)%$$ with respect to $math%alp%$$ $rend
$italic R_bOut$$
	$cend $math%R_i_b(alp, b)%$$ 
	$cend derivative of $math%R_i(alp, b)%$$ with respect to $math%b%$$ $rend
$italic DOut$$ 
	$cend $math%D(alp)%$$ 
	$cend model for the variance of $math%b%$$ $rend
$italic D_alpOut$$
	$cend $math%D_alp(alp)%$$ 
	$cend derivative of $math%D(alp)%$$ with respect to $math%alp%$$
$tend
$syntax/

/J/
/$$
Number simulations of random effects (each simulation corresponds to
a value for all subjects).
$syntax/

/y/
/$$
is a double-precision column vector that contains
the data for all the individuals.
The vector $italic y$$ has
$math%
	N(1) + N(2) + ... + N(M)
%$$
elements where $math%M%$$ is the number of rows in $italic N$$.
The data vector corresponding to the first individual is
$math%
	                                     T
	y_1 = [ y(1) , y(2) , ... , y(N(1)) ]
%$$
Elements $math%y(N(1) + 1)%$$ through $math%y(N(1) + N(2))%$$ 
correspond to the second individual and so on.
(Note that $math%y_1%$$ refers to the first subvector or $italic y$$ while
$math%y(1)%$$ refers to the first element of the vector $italic y$$.)

$syntax/

/N/
/$$
is an integer column vector. 
The $th i$$ element of $italic N$$
specifies the number of elements of $italic y$$ that
correspond to the $th i$$ individual.
$syntax/

/eps/
/$$
Is a double-precision scalar greater than zero. 
A random population parameter value $math%b0%$$ is 
accepted as the point at which to make the
Hessian approximation when 
$math%
	abs(b0 - bHat) #le eps (bUp - bLow)
%$$
where $math%abs%$$ is the element-by-element absolute value function
and $math%bHat%$$ is the true minimizer of 
$xref/Lambda//Lambda(alp, b)/$$ with respect to $math%b%$$.
This is a rough approximation that is quick to
calculate during the optimization procedure.
$syntax/

/delta/
/$$
is a double-precision scalar greater than zero.
A random population parameter value $math%b0%$$ is 
accepted as the point at which to make the
Hessian approximation when
$math%
	Lmabda(alp, b0) - Lambda(alp, bHat) #le delta
%$$
where $math%bHat%$$ is its true minimizer of $math%Lambda(alp, b)%$$.
$syntax/

/mitr/
/$$
this integer scalar specifies the maximum number of 
iterations to attempt before giving up on convergence
of the random population parameter values.
$syntax/

/level/
/$$
this integer scalar specifies the amount of tracing during the
determination of the optimal random population values.
$math%
level #ge 1
%$$
the current value of the objective is printed
with the label $code f$$ and the norm of the gradient is
printed with the label $code |g|$$ 
(not including the constrained directions in the gradient).
In addition, the total time between calling $code mapOpt$$ and its
return is printed.
$math%
level #ge 2
%$$
the current value of $math%b%$$ is 
printed with the label $code x$$, and the gradient of the
objective is printed with the label $code g$$
(not including the constrained directions in the gradient).
$math%
level #ge 3
%$$
the step size and function values are traced
during each line search procedure.
$math%
level #ge 4
%$$
the analytic of the objective function with respect to the
$math%b%$$ is compared with its numerical approximation.
$syntax/

/alp/
/$$
The double-precision column vector $italic alp$$
specifies a value for the fixed population parameter vector.
$syntax/

/alpStep/
/$$
The double-precision column vector $italic alpStep$$
specifies the step size used for approximating
the derivatives with respect to the random population parameters.
$syntax/

/bLow/
/$$
The double-precision column vector $italic bLow$$
specifies the lower limit for the parameter vector 
$math%b%$$ during the optimization procedure.
All the elements of this vector must be less than or equal zero.
$syntax/

/bUp/
/$$
The double-precision column vector $italic bUp$$
specifies the upper limit for the parameter vector 
$math%b%$$ during the optimization procedure.
All the elements of this vector must be greater than or equal zero.
$syntax/

/bStep/
/$$
The double-precision column vector $italic bStep$$
specifies the step size used for approximating
the derivatives with respect to the random population parameters.
$syntax/

/bIn/
/$$
The double-precision matrix $italic bIn$$
specifies the initial value for the search for
the optimal random population parameter vectors.
The $th i$$ column of $italic bIn$$ corresponds to the $th i$$ individual.
$syntax/

/bOut/
/$$
the output value $italic bOut$$
is a matrix with the same type and dimension as $italic bIn$$.
The $th i$$ column of $italic bOut$$ contains
the optimal random population parameters that correspond to the 
$th i$$ individual and the current value of $italic alp$$.
$syntax/

/LowOut/
/$$
the output value $italic LowOut$$
is an integer vector with the same dimension as $italic bLow$$.
The $th i$$ element of $italic bLow$$ contains
the number of simulation values for the random effects where the
$th i$$ element of the random effects was
lower than $italic bLow$$.
$syntax/

/UpOut/
/$$
the output value $italic UpOut$$
is an integer vector with the same dimension as $italic bUp$$.
The $th i$$ element of $italic bUp$$ contains
the number of simulation values for the random effects where the
$th i$$ element of the random effects was
lower than $italic bUp$$.
$syntax/

/LMonteOut/
/$$
the output value $italic LMonteOut$$ is a scalar that contains
the importance sampling Monte-Carlo approximation for the 
negative log of the marginal likelihood.
$syntax/

/SigOut/
/$$
the output value $italic SigOut$$ is a scalar that contains
an approximation for the standard deviation
of $italic LMonteOut$$ as an estimate of the marginal likelihood.
$syntax/

/LMonte_alpOut/
/$$
the output value $italic LMonte_alpOut$$ is a row vector that is equal to
the Monte-Carlo approximation for the derivative with respect to $math%alp%$$
of marginal likelihood.
$syntax/

/Sig_alpOut/
/$$
the output value $italic Sig_alpOut$$ is a scalar that contains
an approximation for the standard deviation
of $italic LMonte_alpOut$$ as an estimate of the
derivative of the marginal likelihood.
$syntax/

/LMonte_alp_alpOut/
/$$
the output value $italic LMonte_alpOut$$ is a row vector that is equal to
the Monte-Carlo approximation for the second 
derivative with respect to $math%alp%$$
of marginal likelihood.
$syntax/

/Sig_alp_alpOut/
/$$
the output value $italic Sig_alp_alpOut$$ is a scalar that contains
an approximation for the standard deviation
of $italic LMonte_alpOut$$ as an estimate of the
derivative of the marginal likelihood.

$head Example$$
Suppose that there are two subjects and for each subject
$math%
	               / 1    0 \
	R_i (alp, b) = |        |
	               \ 0    2 /

	               / b \
	f_i(alp, b)  = |   |
	               \ b /

	               / 1 \
	y_i          = |   |
	               \ 1 /

	D(alp)       = alp
%$$
It follows that
$math%                         
Lambda_i (alp, b) = (1/2) #log{8 #pi^2}   + (3/4)(1 - b)^2
                  + (1/2) #log{2 #pi alp} + (1/2) b^2 / alp
%$$
It follows that the Hessian of $math%Lambda_i (alp, b)%$$
with respect to $math%b%$$ is
$math%
	3 / 2 + 1 / alp
%$$
In addition, the optimal value of $math%b%$$ solves the equation
$math%
	0   = -2 (3/4)(1 - b) +  b / alp
	0   = 1 - b - 2 b / (3 alp)
	1   = [1 + 2 / (3 alp)] b
	b   = 3 alp / (3 alp + 2)

%$$

Note that in this example,
the model function is linear,
and the data variance does not depend on the random effects.
Thus the three objective functions actually have the same value.

If you enter
$codep
clear
include LMonte.oms
include ranseed.oms
#
function objCheck(alp, bOut, LOut, L_alpOut, L_alp_alpOut) begin
	H         = + 3. / 2. +  alp^(-1)
	H_alp     = - alp^(-2)
	H_alp_alp = + 2 * alp^(-3)
	#
	# 3 * alp / (3 * alp + 2)
	b  = 3 * ( 3 + 2 * alp^(-1) )^(-1)
	#
	#  3 * ( 3 + 2 * alp^(-1) )^(-2) * (-1) * (-2) * alp^(-2)
	b_alp = 6 * ( 3 * alp + 2 )^(-2)
	#
	# 6 * (3 * alp + 2)^(-3) * (-2) * 3
	b_alp_alp = - 36 * (3 * alp + 2)^(-3)         
	#
	Lambda = ...
		+ .5 * log(8. * pi^2) ...
		+ .75 * (1. - b)^2 ...
		+ .5 * log(2. * pi * alp) ...
		+ .5 * b^2 * alp^(-1)
	#
	Lambda_alp = ...
		- 1.5 * (1. - b) * b_alp ...
		+ .5 * alp^(-1) ...
		+  b * alp^(-1) * b_alp ...
	      - .5 * b^2 * alp^(-2)
	#
	Lambda_alp_alp = ...
		- 1.5 * (1. - b) * b_alp_alp ...
		+ 1.5 * b_alp * b_alp ...
		- .5 * alp^(-2) ...
		+ b * alp^(-1) * b_alp_alp ...
		+ b_alp * alp^(-1) * b_alp ...
		- b * alp^(-2) * b_alp ...
	      - b * b_alp * alp^(-2) ...
	      + b^2 * alp^(-3)	
	#
	bOut         = [b, b]
	#
	LOut         = 2 * Lambda + log(H/(2 * pi))
	#
	L_alpOut     = 2 * Lambda_alp + H_alp / H
	#
	L_alp_alpOut = 2 * Lambda_alp_alp + H_alp_alp / H - H_alp * H_alp / H^2
end
function Model(i, alp, b, fOut, f_alpOut, f_bOut, ROut, R_alpOut, R_bOut, DOut, D_alpOut) begin
	if fOut then ...
		fOut = {b, b}
	if f_alpOut then ...
		f_alpOut = { ...
		0., ...
		0. ...
	}
	if f_bOut then ...
		f_bOut = { ...
		1., ...
		1. ...
	}
	if ROut then ...
		ROut = { ...
		[ 1. ,  0. ], ...
		[ 0.  , 2. ] ...
	}
	if R_alpOut then ...
		R_alpOut = { ...
		0, ...
		0, ...
		0, ...
		0 ...
	}
	if R_bOut then ...
		R_bOut = { ...
		0., ...
		0., ...
		0., ...
		0. ...
		}
	if DOut then ...
		DOut = { ...
		alp ...
	}
	if D_alpOut then ...
		D_alpOut = { ...
		1. ...
	}
	return true
end
J              = 10
y              = {1., 1., 1., 1.}
N              = {2., 2.}
eps            = 1e-5
delta          = 1e-7
mitr           = 40
level          = 0
alp            = 2.1
alpStep        = 1e-2
bLow           = -20.
bUp            = +20.
bStep          = 1e-2
bIn            = [0., 0.]
bOut           = true
LowOut         = true
UpOut          = true
LOut           = true
SigOut         = true
L_alpOut       = true
Sig_alpOut     = true
L_alp_alpOut   = true
Sig_alp_alpOut = true
#
ranseed
ok = LMonte( ...
	function Model, ...
	J, ...
	y,  ...
	N, ...
	eps, ...
	delta, ...
	mitr, ...
	level, ...
	alp, alpStep, ...
	bLow, bUp, bStep,  ...
	bIn, bOut, ...
	LowOut, UpOut, ...
	LOut, SigOut, ...
	L_alpOut, Sig_alpOut, ...
	L_alp_alpOut, Sig_alp_alpOut ...
)
#
bCheck         = novalue
LCheck         = novalue
L_alpCheck     = novalue
L_alp_alpCheck = novalue
objCheck(alp, bCheck, LCheck, L_alpCheck, L_alp_alpCheck)
#
print "ok                          =", ok
print "[bOut, bCheck]              =", [bOut, bCheck]
print "[LOut,         Check, Sig ] =", [LOut, LCheck, SigOut]
print "[L_alpOut,     Check, Sig ] =", [L_alpOut, L_alpCheck, Sig_alpOut]
print "[L_alp_alpOut, Check, Sig ] =", [L_alp_alpOut, L_alp_alpCheck, Sig_alp_alpOut ]  
print "[LowOut, UpOut]             =", [LowOut, UpOut]

$$
$pre

$$
$center
$italic
$include shortCopyright.txt$$
$$
$$
$end
---------------------------------------------------------------------
#end##
#
include Lambda.oms
include MonteLaplace.oms
#
local function [f, h] = Fun(function Model_i, y_i, alp, b) begin
	Lam     = true
	Lam_alp = false
	Lam_b   = false
	ok = Lambda( ...
		function Model_i, ...
		y_i,  ...
		alp, ...
		b, ...
		Lam, ...
		Lam_alp, ...
		Lam_b ...
	)
	f = Lam
	# p(y|alp): h = term multiplying exp[-Lambda(alp, b, y)]
	h = 1d0
end
local function [f, h] = Fun_alp(function Model_i, y_i, alp, b) begin
	Lam     = true
	Lam_alp = true
	Lam_b   = false
	ok = Lambda( ...
		function Model_i, ...
		y_i,  ...
		alp, ...
		b, ...
		Lam, ...
		Lam_alp, ...
		Lam_b ...
	)
	f = Lam
	# p(y|alp)_alp : h = term multiplying exp[-Lambda(alp, b, y)]
	h = -Lam_alp
end
local function [f, h] = Fun_alp_alp(alpStep, function Model_i, y_i, alp, b) begin
	f = Fun(function Model_i, y_i, alp, b)
	#
	bStep       = 0 * b
	Lam_alp     = true
	Lam_alp_alp = true
	Lam_alp_b   = false
	ok = LambdaDiff( ...
		function Model_i, ...
		y_i,  ...
		alp, alpStep, ...
		b, bStep, ...
		"alp", ...
		Lam_alp, Lam_alp_alp, Lam_alp_b ...
	)
	# p(y|alp)_alp_alp : h = term multiplying exp[-Lambda(alp, b, y)]
	h = Lam_alp' * Lam_alp - Lam_alp_alp
end
function LMonte( ...
	function Model, ...
	J, ...
	y,  ...
	N, ...
	eps, ...
	delta, ...
	mitr, ...
	level, ...
	alp, alpStep, ...
	bLow, bUp, bStep,  ...
	bIn, bOut, ...
	LowOut, UpOut, ...
	LMonteOut, SigOut, ...
	LMonte_alpOut, Sig_alpOut, ...
	LMonte_alp_alpOut, Sig_alp_alpOut  ...
) begin
	#
	# some constants
	nsub = rowdim(N)    # number of subjects
	nalp = rowdim(alp)  # number of fixed population parameters
	nb   = rowdim(bIn)  # number of random population parameters per subject	
	#
	# initialize for summation over subjects
	L                 = 0
	SigSq             = 0
	L_alp             = 0
	Sig_alpSq         = 0
	L_alp_alp         = 0
	Sig_alp_alpSq     = 0
	yindex            = 1
	Low               = 0
	Up                = 0
	bMin              = fill(0, nb, nsub)
	#
	# loop over subjects
	for i = 1 to nsub begin
		#
		# Number of data values for this subject
		N_i = N(i)
		#
		# data for this subject
		y_i    = y.row(yindex, N_i)
		yindex = yindex + N_i
		#
		# initial random population parameter value
		b_i = bIn.col(i)
		#
		# model function for this subect
		SubjectIndex     = i # cannot use a loop index as a replacement argument
		function Model_i = Model(SubjectIndex)
		#
		# compute the random population estimate for this subject
		#
		blsq       = false
		bHat       = false
		bTilde     = true
		bTilde_alp = false
		ok = EstimateB( ...
			function Model_i, ...
			blsq, ...
			y_i,  ...
			eps, ...
			delta, ...
			mitr, ...
			level, ...
			alp, ...
			b_i, bLow, bUp, bHat, bTilde, bStep,  ...
			bTilde_alp ...
		)
		if not ok then begin
			stop
			return false
		end
		bMin.col(i) = bTilde
		#
		# compute the approximation to the Hessian
		#
		HTilde     = true
		HTilde_alp = false
		HTilde_b   = false
		ok = Lambda2Diff( ...
			function Model_i, ...
			y_i, ...
			alp, ...
			bTilde, ...
			bStep, ...
			HTilde, ...
			HTilde_alp, ...
			HTilde_b ...
		)
		if not ok then begin
			stop
			return false
		end
		#
		# Monte Carlo approximation for the marginal likelihood
		function fun = Fun(Model_i, y_i, alp)
		[I, Isig, low, up] = ...
			MonteLaplace(function fun, J, bLow, bUp, bTilde, HTilde)
		#
		# renormalize
		I    = exp(-fun(bTilde)) * I
		Isig = exp(-fun(bTilde)) * Isig
		#
		# add contribution for this subject to marginal likelihood
		L      = L - log(I)
		SigSq  = SigSq + Isig^2
		#
		# add contribution to out of limits count
		Low = Low + low
		Up  = Up  + up
		#
		# Monte Carlo approximation for the derivative of marginal likelihood
		if LMonte_alpOut or LMonte_alp_alpOut then begin
			function fun = Fun_alp(Model_i, y_i, alp)
			[I_alp, I_alpSig, low, up] = ...
				MonteLaplace(function fun, J, bLow, bUp, bTilde, HTilde)
			#
			# renormalize
			I_alp    = exp(-fun(bTilde)) * I_alp
			I_alpSig = exp(-fun(bTilde)) * I_alpSig
			#
			# add contribution for this subject to marginal likelihood
			L_alp      = L_alp - I_alp / I
			Sig_alpSq  = Sig_alpSq + (I_alpSig / I)^2 + (I_alp * Isig / I^2)^2
			#
			# add contribution to out of limits count
			Low = Low + low
			Up  = Up  + up
		end
		#
		# Monte Carlo approximation for the derivative of marginal likelihood
		if LMonte_alp_alpOut then begin
			function fun = Fun_alp_alp(alpStep, Model_i, y_i, alp)
			[I_alp_alp, I_alp_alpSig, low, up] = ...
				MonteLaplace(function fun, J, bLow, bUp, bTilde, HTilde)
			#
			# renormalize
			I_alp_alp    = exp(-fun(bTilde)) * I_alp_alp
			I_alp_alpSig = exp(-fun(bTilde)) * I_alp_alpSig
			#
			# add contribution for this subject to marginal likelihood
			L_alp_alp     = L_alp_alp + I_alp' * I_alp / I^2 - I_alp_alp / I
			Sig_alp_alpSq = Sig_alp_alpSq ...
				+ (I_alp' * I_alpSig / I^2)^2 ...
				+ (I_alpSig' * I_alp / I^2)^2 ...
				+ (2 * I_alp' * I_alp * Isig / I^3)^2 ...
				+ (I_alp_alpSig / I)^2 ...
				+ (I_alp_alp * Isig / I^2)
			#
			# add contribution to out of limits count
			Low = Low + low
			Up  = Up  + up
		end
	end
	if bOut then ...
		bOut = bMin
	if LowOut then ...
		LowOut = Low
	if UpOut then ...
		UpOut = Up
	if LMonteOut then ...
		LMonteOut = L
	if SigOut then ...
		SigOut = sqrt(SigSq)
	if LMonte_alpOut then ...
		LMonte_alpOut = L_alp
	if Sig_alpOut then ...
		Sig_alpOut = sqrt(Sig_alpSq)
	if LMonte_alp_alpOut then ...
		LMonte_alp_alpOut = L_alp_alp
	if Sig_alp_alpOut then ...
		Sig_alp_alpOut = sqrt(Sig_alp_alpSq)
	#
	return true
end

end # blocking for automatic include
